{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1aBfZJB1mbRoAAgbFUaz7bBdwWxUIp1El","authorship_tag":"ABX9TyNPJXy/j4WtOsR9dvBgqOVi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"buzByLwk64-V","executionInfo":{"status":"ok","timestamp":1761462404510,"user_tz":240,"elapsed":45,"user":{"displayName":"Jason Rayan","userId":"12984511507835942150"}},"outputId":"0a9ef7c9-6c86-48dd-bd76-dca331c322a5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Imports complete\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from typing import List, Dict, Tuple, Optional\n","import time\n","from pathlib import Path\n","\n","print(\"Imports complete\")"]},{"cell_type":"code","source":["EMBEDDINGS_PATH = \"/content/embeddings.parquet\"  # or embeddings_series.parquet\n","RAW_DATA_PATH = \"/content/raw_data.csv\"\n","CLEANED_DATA_PATH = \"/content/cleaned_data_names.parquet\"\n","\n","# Search parameters\n","DEFAULT_K = 10\n","DEFAULT_CANDIDATES = 100\n","\n","print(\"Configuration set\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"88DjnGc37Fra","executionInfo":{"status":"ok","timestamp":1761462406046,"user_tz":240,"elapsed":8,"user":{"displayName":"Jason Rayan","userId":"12984511507835942150"}},"outputId":"7043e6a1-e0e0-4b47-f1a5-93e80a011774"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Configuration set\n"]}]},{"cell_type":"markdown","source":["\n","# DATA LOADING\n"],"metadata":{"id":"6f5mCF107TqZ"}},{"cell_type":"code","source":["def load_data():\n","    \"\"\"Load all necessary data files\"\"\"\n","    print(\"Loading data files...\")\n","\n","    # Load embeddings\n","    emb_df = pd.read_parquet(EMBEDDINGS_PATH)\n","    embeddings = np.vstack(emb_df['embedding'].values)\n","    print(f\"‚úì Embeddings loaded: {embeddings.shape}\")\n","\n","    # Load metadata\n","    metadata = pd.read_parquet(CLEANED_DATA_PATH)\n","    print(f\"‚úì Metadata loaded: {len(metadata)} rows\")\n","\n","    # Load raw data for display\n","    raw_data = pd.read_csv(RAW_DATA_PATH)\n","    print(\"Check 1\")\n","    raw_data[\"anime_id\"] = pd.to_numeric(raw_data[\"anime_id\"], errors=\"coerce\")\n","    print(f\"‚úì Raw data loaded: {len(raw_data)} rows\")\n","\n","    # Verify alignment\n","    assert len(embeddings) == len(emb_df) == len(metadata), \"Data size mismatch!\"\n","\n","    return embeddings, emb_df, metadata, raw_data\n","\n","embeddings, emb_df, metadata, raw_data = load_data()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Aave4NvE7JPk","executionInfo":{"status":"ok","timestamp":1761462408810,"user_tz":240,"elapsed":976,"user":{"displayName":"Jason Rayan","userId":"12984511507835942150"}},"outputId":"e4b2087b-e0e6-49ee-9122-09ce4724d4d5"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading data files...\n","‚úì Embeddings loaded: (8857, 768)\n","‚úì Metadata loaded: 8857 rows\n","Check 1\n","‚úì Raw data loaded: 15000 rows\n"]}]},{"cell_type":"markdown","source":["# KNN SEARCH FUNCTIONS"],"metadata":{"id":"wOyJ4r3Z7jTJ"}},{"cell_type":"code","source":["def cosine_similarity_batch(query_vec: np.ndarray,\n","                           embeddings: np.ndarray) -> np.ndarray:\n","    \"\"\"\n","    Compute cosine similarity between query and all embeddings.\n","    Assumes both query_vec and embeddings are already L2-normalized.\n","    \"\"\"\n","    return np.dot(embeddings, query_vec)\n","\n","\n","def knn_search(query_vec: np.ndarray,\n","               embeddings: np.ndarray,\n","               k: int = 10,\n","               exclude_idx: Optional[int] = None) -> Tuple[np.ndarray, np.ndarray]:\n","    \"\"\"\n","    Find k nearest neighbors using cosine similarity.\n","\n","    Returns:\n","        indices: array of k indices\n","        similarities: array of k similarity scores\n","    \"\"\"\n","    sims = cosine_similarity_batch(query_vec, embeddings)\n","\n","    # Get top-k\n","    K = min(k + (1 if exclude_idx is not None else 0), len(embeddings))\n","    top_indices = np.argpartition(-sims, K-1)[:K]\n","    top_indices = top_indices[np.argsort(-sims[top_indices])]\n","\n","    # Exclude query index if specified\n","    if exclude_idx is not None:\n","        top_indices = top_indices[top_indices != exclude_idx]\n","\n","    return top_indices[:k], sims[top_indices[:k]]\n","\n","\n","def approximate_knn_search(query_vec: np.ndarray,\n","                          embeddings: np.ndarray,\n","                          k: int = 10,\n","                          probe_size: int = 1000) -> Tuple[np.ndarray, np.ndarray]:\n","    \"\"\"\n","    Faster approximate KNN using random sampling for very large datasets.\n","    Useful when exact search is too slow.\n","    \"\"\"\n","    n = len(embeddings)\n","    if n <= probe_size or probe_size >= n:\n","        return knn_search(query_vec, embeddings, k)\n","\n","    # Random sample\n","    sample_idx = np.random.choice(n, size=probe_size, replace=False)\n","    sample_emb = embeddings[sample_idx]\n","\n","    # Search in sample\n","    local_top, local_sims = knn_search(query_vec, sample_emb, k)\n","\n","    # Map back to original indices\n","    global_indices = sample_idx[local_top]\n","    return global_indices, local_sims"],"metadata":{"id":"48RzR08S7lRw","executionInfo":{"status":"ok","timestamp":1761462415097,"user_tz":240,"elapsed":6,"user":{"displayName":"Jason Rayan","userId":"12984511507835942150"}}},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":["# QUERY PROCESSING"],"metadata":{"id":"SF3Xouss75ej"}},{"cell_type":"code","source":["def find_anime_by_name(query_name: str,\n","                       metadata: pd.DataFrame,\n","                       search_columns: List[str] = None) -> Optional[int]:\n","    \"\"\"\n","    Find anime index by searching in name columns.\n","    Returns the first match found.\n","    \"\"\"\n","    if search_columns is None:\n","        search_columns = [\"name\", \"english_name\", \"japanese_names\", \"embed_text\"]\n","\n","    for col in search_columns:\n","        if col not in metadata.columns:\n","            continue\n","\n","        mask = metadata[col].astype(str).str.contains(\n","            query_name, case=False, na=False, regex=False\n","        )\n","        hits = metadata[mask].index.tolist()\n","\n","        if hits:\n","            if len(hits) > 1:\n","                print(f\"Found {len(hits)} matches in '{col}', using first match\")\n","            return hits[0]\n","\n","    return None\n","\n","\n","def create_query_embedding(query_text: str,\n","                          model) -> np.ndarray:\n","    \"\"\"\n","    Create embedding for a text query using the same model.\n","    Requires: vertexai TextEmbeddingModel initialized\n","    \"\"\"\n","    from vertexai.language_models import TextEmbeddingModel\n","\n","    resp = model.get_embeddings([query_text])\n","    emb = np.asarray(resp[0].values, dtype=np.float32)\n","\n","    # L2 normalize\n","    norm = np.linalg.norm(emb)\n","    if norm > 0:\n","        emb = emb / norm\n","\n","    return emb"],"metadata":{"id":"2pfLH_sV77KW","executionInfo":{"status":"ok","timestamp":1761462417105,"user_tz":240,"elapsed":7,"user":{"displayName":"Jason Rayan","userId":"12984511507835942150"}}},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":["# RESULT FILTERING"],"metadata":{"id":"KhuiKJqe8CLp"}},{"cell_type":"code","source":["def filter_same_series(candidate_indices: np.ndarray,\n","                      query_idx: int,\n","                      metadata: pd.DataFrame,\n","                      use_aggressive: bool = True) -> np.ndarray:\n","    \"\"\"\n","    Remove sequels/related entries from the same series.\n","    Uses multiple strategies for robust filtering.\n","\n","    Args:\n","        candidate_indices: Array of candidate indices to filter\n","        query_idx: Index of the query anime\n","        metadata: DataFrame with anime metadata\n","        use_aggressive: If True, uses more aggressive title matching\n","    \"\"\"\n","    import re\n","\n","    query_row = metadata.iloc[query_idx]\n","    query_name = str(query_row.get('name', '')).strip()\n","\n","    if not query_name:\n","        return candidate_indices\n","\n","    # Try series_key first\n","    if 'series_key' in metadata.columns:\n","        query_key = str(query_row.get('series_key', '')).strip().lower()\n","\n","        def same_series(idx):\n","            if idx == query_idx:\n","                return True\n","            target_key = str(metadata.iloc[idx].get('series_key', '')).strip().lower()\n","            return query_key and target_key and (query_key == target_key)\n","    else:\n","        # Fallback to title matching\n","        query_title = str(query_row.get('name', '')).lower()\n","        query_root = ' '.join(query_title.split()[:2])\n","\n","        def same_series(idx):\n","            if idx == query_idx:\n","                return True\n","            target_title = str(metadata.iloc[idx].get('name', '')).lower()\n","            return query_root and target_title.startswith(query_root)\n","\n","    filtered = [idx for idx in candidate_indices if not same_series(idx)]\n","    return np.array(filtered)\n","\n","\n","def mmr_rerank(candidate_embeddings: np.ndarray,\n","               query_vec: np.ndarray,\n","               lambda_mult: float = 0.7,\n","               top_n: int = 10) -> List[int]:\n","    \"\"\"\n","    Maximal Marginal Relevance re-ranking for diversity.\n","\n","    Args:\n","        candidate_embeddings: (N, dim) embeddings of candidates\n","        query_vec: (dim,) query embedding\n","        lambda_mult: relevance vs diversity tradeoff (higher = more relevant)\n","        top_n: number of results to return\n","    \"\"\"\n","    selected = []\n","    remaining = list(range(len(candidate_embeddings)))\n","\n","    # Precompute query similarities\n","    query_sims = np.dot(candidate_embeddings, query_vec)\n","\n","    for _ in range(min(top_n, len(candidate_embeddings))):\n","        if not remaining:\n","            break\n","\n","        mmr_scores = []\n","        for idx in remaining:\n","            rel = query_sims[idx]  # Relevance to query\n","\n","            if selected:\n","                # Diversity: max similarity to already selected\n","                selected_emb = candidate_embeddings[selected]\n","                div = np.max(np.dot(selected_emb, candidate_embeddings[idx]))\n","            else:\n","                div = 0\n","\n","            mmr = lambda_mult * rel - (1 - lambda_mult) * div\n","            mmr_scores.append((mmr, idx))\n","\n","        # Select best MMR score\n","        best_idx = max(mmr_scores, key=lambda x: x[0])[1]\n","        selected.append(best_idx)\n","        remaining.remove(best_idx)\n","\n","    return selected\n","\n","\n","def diversify_by_genre(candidate_indices: List[int],\n","                      metadata: pd.DataFrame,\n","                      max_per_genre: int = 2) -> List[int]:\n","    \"\"\"\n","    Ensure genre diversity by limiting entries per genre.\n","    \"\"\"\n","    genre_counts = {}\n","    diverse = []\n","\n","    for idx in candidate_indices:\n","        genres = metadata.iloc[idx].get('genre_theme_set', [])\n","        if isinstance(genres, str):\n","            genres = [genres]\n","        elif not isinstance(genres, (list, tuple)):\n","            genres = []\n","\n","        main_genre = genres[0] if genres else \"Unknown\"\n","\n","        if genre_counts.get(main_genre, 0) < max_per_genre:\n","            diverse.append(idx)\n","            genre_counts[main_genre] = genre_counts.get(main_genre, 0) + 1\n","\n","    return diverse"],"metadata":{"id":"4heghH2M8E6u","executionInfo":{"status":"ok","timestamp":1761462418956,"user_tz":240,"elapsed":22,"user":{"displayName":"Jason Rayan","userId":"12984511507835942150"}}},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":["# RECOMMENDATION MAIN"],"metadata":{"id":"XBjAhqOF8ZZu"}},{"cell_type":"code","source":["def recommend_anime(query_name: str,\n","                   embeddings: np.ndarray,\n","                   metadata: pd.DataFrame,\n","                   raw_data: pd.DataFrame,\n","                   k: int = 10,\n","                   candidates: int = 100,\n","                   use_mmr: bool = True,\n","                   lambda_mult: float = 0.7,\n","                   filter_series: bool = True,\n","                   diversify_genres: bool = True,\n","                   verbose: bool = True) -> List[Dict]:\n","    \"\"\"\n","    Complete recommendation pipeline.\n","\n","    Args:\n","        query_name: Anime title to search for\n","        embeddings: Pre-computed embeddings array\n","        metadata: DataFrame with anime metadata\n","        raw_data: DataFrame with display information\n","        k: Number of recommendations to return\n","        candidates: Number of initial candidates to consider\n","        use_mmr: Apply MMR re-ranking for diversity\n","        lambda_mult: MMR relevance weight (0-1)\n","        filter_series: Remove same-series entries\n","        diversify_genres: Ensure genre diversity\n","        verbose: Print detailed output\n","\n","    Returns:\n","        List of recommendation dictionaries\n","    \"\"\"\n","    start_time = time.time()\n","\n","    # 1. Find query anime\n","    query_idx = find_anime_by_name(query_name, metadata)\n","    if query_idx is None:\n","        print(f\"‚ùå '{query_name}' not found in database\")\n","        return []\n","\n","    query_row = metadata.iloc[query_idx]\n","    query_anime_id = query_row.get('anime_id')\n","\n","    if verbose:\n","        print(f\"üìå Query: {query_row.get('name', 'Unknown')} (ID: {query_anime_id}, Index: {query_idx})\")\n","        print(f\"{'='*80}\")\n","\n","    # 2. Get initial candidates\n","    query_vec = embeddings[query_idx]\n","    cand_indices, cand_sims = knn_search(\n","        query_vec, embeddings,\n","        k=candidates,\n","        exclude_idx=query_idx\n","    )\n","\n","    # 3. Filter same series\n","    if filter_series:\n","        cand_indices = filter_same_series(cand_indices, query_idx, metadata)\n","        if len(cand_indices) == 0:\n","            print(\"‚ö†Ô∏è  All candidates filtered out, using top results without filtering\")\n","            cand_indices, _ = knn_search(query_vec, embeddings, k=k, exclude_idx=query_idx)\n","\n","    # 4. MMR re-ranking\n","    if use_mmr and len(cand_indices) > k:\n","        cand_emb = embeddings[cand_indices]\n","        mmr_order = mmr_rerank(cand_emb, query_vec, lambda_mult, top_n=k*3)\n","        cand_indices = cand_indices[mmr_order]\n","\n","    # 5. Genre diversity\n","    if diversify_genres:\n","        cand_indices = diversify_by_genre(cand_indices[:k*2], metadata, max_per_genre=3)\n","\n","    # 6. Final selection\n","    final_indices = cand_indices[:k]\n","\n","    # 7. Prepare results with lookups\n","    results = []\n","    for rank, idx in enumerate(final_indices, 1):\n","        anime_id = metadata.iloc[idx].get('anime_id')\n","        sim_score = cosine_similarity_batch(query_vec, embeddings[idx:idx+1])[0]\n","\n","        # Lookup in raw_data\n","        info = raw_data[raw_data['anime_id'] == anime_id]\n","        if not info.empty:\n","            name = info.iloc[0].get('name', 'Unknown')\n","            score = info.iloc[0].get('score', 'N/A')\n","            episodes = info.iloc[0].get('episodes', 'N/A')\n","            genres = info.iloc[0].get('genres', 'N/A')\n","        else:\n","            name = metadata.iloc[idx].get('name', 'Unknown')\n","            score = metadata.iloc[idx].get('score', 'N/A')\n","            episodes = metadata.iloc[idx].get('episodes', 'N/A')\n","            genres = 'N/A'\n","\n","        result = {\n","            'rank': rank,\n","            'anime_id': anime_id,\n","            'name': name,\n","            'similarity': float(sim_score),\n","            'score': score,\n","            'episodes': episodes,\n","            'genres': genres\n","        }\n","        results.append(result)\n","\n","        if verbose:\n","            print(f\"{rank:2d}. [{anime_id:6d}] {name[:50]:50s} | sim={sim_score:.4f} | score={score} | eps={episodes}\")\n","\n","    elapsed = time.time() - start_time\n","    if verbose:\n","        print(f\"{'='*80}\")\n","        print(f\"‚è±Ô∏è  Search completed in {elapsed:.3f}s\")\n","\n","    return results"],"metadata":{"id":"ZDvuxceZ8cYk","executionInfo":{"status":"ok","timestamp":1761462421707,"user_tz":240,"elapsed":15,"user":{"displayName":"Jason Rayan","userId":"12984511507835942150"}}},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":["# TESTING"],"metadata":{"id":"pRrCUyA68itx"}},{"cell_type":"code","source":["def test_series_filtering(query_name: str,\n","                         embeddings: np.ndarray,\n","                         metadata: pd.DataFrame,\n","                         top_n: int = 50):\n","    \"\"\"\n","    Test function to verify same-series filtering is working.\n","    Shows what gets filtered and what remains.\n","    \"\"\"\n","    print(f\"\\n{'='*80}\")\n","    print(f\"TESTING SERIES FILTER FOR: {query_name}\")\n","    print(f\"{'='*80}\")\n","\n","    # Find query\n","    query_idx = find_anime_by_name(query_name, metadata)\n","    if query_idx is None:\n","        print(f\"‚ùå '{query_name}' not found\")\n","        return\n","\n","    query_row = metadata.iloc[query_idx]\n","    print(f\"\\nüìå Query Anime:\")\n","    print(f\"   Name: {query_row.get('name', 'Unknown')}\")\n","    print(f\"   ID: {query_row.get('anime_id')}\")\n","    if 'series_key' in metadata.columns:\n","        print(f\"   Series Key: {query_row.get('series_key', 'N/A')}\")\n","\n","    # Get candidates without filtering\n","    query_vec = embeddings[query_idx]\n","    cand_indices, cand_sims = knn_search(\n","        query_vec, embeddings,\n","        k=top_n,\n","        exclude_idx=query_idx\n","    )\n","\n","    print(f\"\\nüîç Top {top_n} candidates (before filtering):\")\n","    print(f\"{'='*80}\")\n","\n","    # Apply filtering\n","    filtered_indices = filter_same_series(cand_indices, query_idx, metadata, use_aggressive=True)\n","    filtered_set = set(filtered_indices)\n","\n","    # Show results\n","    for i, idx in enumerate(cand_indices[:20], 1):  # Show top 20\n","        row = metadata.iloc[idx]\n","        name = row.get('name', 'Unknown')\n","        anime_id = row.get('anime_id', 'N/A')\n","        sim = cand_sims[i-1]\n","\n","        is_filtered = idx not in filtered_set\n","        status = \"‚ùå FILTERED\" if is_filtered else \"‚úÖ KEPT\"\n","\n","        print(f\"{i:2d}. [{anime_id:6}] {name[:60]:60s} | sim={sim:.4f} | {status}\")\n","\n","    print(f\"\\n{'='*80}\")\n","    print(f\"üìä Summary:\")\n","    print(f\"   Original candidates: {len(cand_indices)}\")\n","    print(f\"   Filtered out: {len(cand_indices) - len(filtered_indices)}\")\n","    print(f\"   Remaining: {len(filtered_indices)}\")\n","    print(f\"{'='*80}\\n\")\n","print(\"\\n\" + \"=\"*80)\n","print(\"KNN SEARCH SYSTEM READY\")\n","print(\"=\"*80)\n","test_series_filtering(\"One Piece\", embeddings, metadata, top_n=50)\n","# Example 1: Basic recommendation\n","print(\"\\nüîç Example 1: Basic Recommendations\")\n","results = recommend_anime(\"One Piece\", embeddings, metadata, raw_data, k=10, filter_series = True)\n","\n","# Example 2: More diverse results\n","print(\"\\nüîç Example 2: Diverse Recommendations (lower lambda)\")\n","results = recommend_anime(\"One Piece\", embeddings, metadata, raw_data,\n","                         k=10, lambda_mult=0.5)\n","\n","# Example 3: Pure similarity (no MMR)\n","print(\"\\nüîç Example 3: Pure Similarity (no MMR)\")\n","results = recommend_anime(\"One Piece\", embeddings, metadata, raw_data,\n","                         k=10, use_mmr=False)"],"metadata":{"id":"JDw4r0Lt8u_B","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761463196986,"user_tz":240,"elapsed":646,"user":{"displayName":"Jason Rayan","userId":"12984511507835942150"}},"outputId":"064bbde3-b98f-49e6-d50c-fa5a5645cc61"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","KNN SEARCH SYSTEM READY\n","================================================================================\n","\n","================================================================================\n","TESTING SERIES FILTER FOR: One Piece\n","================================================================================\n","Found 22 matches in 'name', using first match\n","\n","üìå Query Anime:\n","   Name: one piece movie 14 stampede\n","   ID: 38234\n","\n","üîç Top 50 candidates (before filtering):\n","================================================================================\n"," 1. [ 60108] one piece gyojin tou hen                                     | sim=0.8622 | ‚ùå FILTERED\n"," 2. [   459] one piece movie 01                                           | sim=0.8309 | ‚ùå FILTERED\n"," 3. [ 31490] one piece film gold                                          | sim=0.8292 | ‚ùå FILTERED\n"," 4. [  2107] one piece movie 08 episode of alabasta sabaku no oujo to kai | sim=0.8191 | ‚ùå FILTERED\n"," 5. [  4155] one piece film strong world                                  | sim=0.8104 | ‚ùå FILTERED\n"," 6. [   464] one piece movie 06 omatsuri danshaku to himitsu no shima     | sim=0.8073 | ‚ùå FILTERED\n"," 7. [ 12859] one piece film z                                             | sim=0.8020 | ‚ùå FILTERED\n"," 8. [   460] one piece movie 02 nejimaki jima no daibouken                | sim=0.7955 | ‚ùå FILTERED\n"," 9. [   463] one piece movie 05 norowareta seiken                         | sim=0.7874 | ‚ùå FILTERED\n","10. [   465] one piece movie 07 karakuri jou no mecha kyohei              | sim=0.7703 | ‚ùå FILTERED\n","11. [   462] one piece movie 04 dead end no bouken                        | sim=0.7699 | ‚ùå FILTERED\n","12. [  3848] one piece movie 09 episode of chopper plus fuyu ni saku kise | sim=0.7669 | ‚ùå FILTERED\n","13. [ 50410] one piece film red                                           | sim=0.7616 | ‚ùå FILTERED\n","14. [ 35972] fairy tail final series                                      | sim=0.7141 | ‚úÖ KEPT\n","15. [   461] one piece movie 03 chinjuu jima no chopper oukoku            | sim=0.7136 | ‚ùå FILTERED\n","16. [ 38419] tokyo one piece tower tongari shima no dai hihou             | sim=0.7116 | ‚úÖ KEPT\n","17. [ 22043] fairy tail 2014                                              | sim=0.7092 | ‚úÖ KEPT\n","18. [ 20961] parol no miraijima                                           | sim=0.6980 | ‚úÖ KEPT\n","19. [  6855] da nao tiangong                                              | sim=0.6953 | ‚úÖ KEPT\n","20. [ 37348] dungeon ni deai wo motomeru no wa machigatteiru darou ka mov | sim=0.6943 | ‚úÖ KEPT\n","\n","================================================================================\n","üìä Summary:\n","   Original candidates: 50\n","   Filtered out: 15\n","   Remaining: 35\n","================================================================================\n","\n","\n","üîç Example 1: Basic Recommendations\n","Found 22 matches in 'name', using first match\n","üìå Query: one piece movie 14 stampede (ID: 38234, Index: 408)\n","================================================================================\n"," 1. [ 35972] Fairy Tail: Final Series                           | sim=0.7141 | score=7.61 | eps=51.0\n"," 2. [ 38419] Tokyo One Piece Tower: Tongari Shima no Dai Hihou  | sim=0.7116 | score=6.56 | eps=1.0\n"," 3. [ 60790] Luffy, Law                                         | sim=0.6910 | score=6.38 | eps=1.0\n","================================================================================\n","‚è±Ô∏è  Search completed in 0.149s\n","\n","üîç Example 2: Diverse Recommendations (lower lambda)\n","Found 22 matches in 'name', using first match\n","üìå Query: one piece movie 14 stampede (ID: 38234, Index: 408)\n","================================================================================\n"," 1. [ 35972] Fairy Tail: Final Series                           | sim=0.7141 | score=7.61 | eps=51.0\n"," 2. [ 38419] Tokyo One Piece Tower: Tongari Shima no Dai Hihou  | sim=0.7116 | score=6.56 | eps=1.0\n"," 3. [ 10012] Carnival Phantasm                                  | sim=0.6708 | score=7.87 | eps=12.0\n","================================================================================\n","‚è±Ô∏è  Search completed in 0.116s\n","\n","üîç Example 3: Pure Similarity (no MMR)\n","Found 22 matches in 'name', using first match\n","üìå Query: one piece movie 14 stampede (ID: 38234, Index: 408)\n","================================================================================\n"," 1. [ 35972] Fairy Tail: Final Series                           | sim=0.7141 | score=7.61 | eps=51.0\n"," 2. [ 38419] Tokyo One Piece Tower: Tongari Shima no Dai Hihou  | sim=0.7116 | score=6.56 | eps=1.0\n"," 3. [ 22043] Fairy Tail (2014)                                  | sim=0.7092 | score=7.66 | eps=102.0\n","================================================================================\n","‚è±Ô∏è  Search completed in 0.036s\n"]}]},{"cell_type":"markdown","source":["# BATCH QUERY"],"metadata":{"id":"ISNxe4fl-mzH"}},{"cell_type":"code","source":["def batch_recommend(anime_names: List[str], **kwargs) -> Dict[str, List[Dict]]:\n","    \"\"\"\n","    Get recommendations for multiple anime at once.\n","    \"\"\"\n","    results = {}\n","    for name in anime_names:\n","        print(f\"\\n{'='*80}\")\n","        results[name] = recommend_anime(name, embeddings, metadata, raw_data,\n","                                       verbose=True, **kwargs)\n","    return results\n","\n","#Example batch usage:\n","batch_results = batch_recommend([\"Naruto\", \"Death Note\", \"Steins;Gate\"], k=5)"],"metadata":{"id":"bZa0QpbJ-oem","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761462534007,"user_tz":240,"elapsed":272,"user":{"displayName":"Jason Rayan","userId":"12984511507835942150"}},"outputId":"65e158f7-9f58-4eb3-b72f-86b2f6d0915d"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","Found 17 matches in 'name', using first match\n","üìå Query: naruto shippuuden (ID: 1735, Index: 295)\n","================================================================================\n"," 1. [    20] Naruto                                             | sim=0.8825 | score=8.01 | eps=220.0\n"," 2. [ 34566] Boruto: Naruto Next Generations                    | sim=0.8712 | score=5.99 | eps=293.0\n"," 3. [ 10686] Naruto: Honoo no Chuunin Shiken! Naruto vs. Konoha | sim=0.8217 | score=7.17 | eps=1.0\n","================================================================================\n","‚è±Ô∏è  Search completed in 0.128s\n","\n","================================================================================\n","üìå Query: death note (ID: 1535, Index: 90)\n","================================================================================\n"," 1. [  5205] Kara no Kyoukai Movie 7: Satsujin Kousatsu (Go)    | sim=0.7384 | score=8.37 | eps=1.0\n"," 2. [   269] Bleach                                             | sim=0.7237 | score=7.98 | eps=366.0\n"," 3. [ 44961] Platinum End                                       | sim=0.7379 | score=6.02 | eps=24.0\n","================================================================================\n","‚è±Ô∏è  Search completed in 0.138s\n","\n","================================================================================\n","‚ùå 'Steins;Gate' not found in database\n"]}]}]}